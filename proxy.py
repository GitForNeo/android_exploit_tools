#!/usr/bin/env python
# encoding: utf-8
"""
@author:     idhyt
@date:       2015年07月07日
@description:
            A Simple HTTP Proxy module. Works on Python 2.7.
            modify base on https://github.com/inaz2/SimpleHTTPProxy.git
            usage:
                sys.argv[0], -i 10.20.238.22 -p 8080
            or:
                usage()
"""

import sys
import httplib
from SocketServer import ThreadingMixIn
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler
from threading import Lock, Timer
from cStringIO import StringIO
from urlparse import urlsplit
import socket
import select
import gzip
import zlib
import re
import traceback
import urlparse
import json
from HTMLParser import HTMLParser
import getopt


# the capture data show in the console or not
IS_SHOW = True


def usage(msg=None):
    if msg:
        print msg
    print sys.argv[0], "[-i ip] [-p port] "
    print
    print "   -i       - Ip to bind, default localhost"
    print "   -p       - Port to bind, default 8080"
    print


def with_color(color, str_value):
    return "\x1b[%dm%s\x1b[0m" % (color, str_value)


class ThreadingHTTPServer(ThreadingMixIn, HTTPServer):
    # listening on IPv4 address
    address_family = socket.AF_INET

    def handle_error(self, request, client_address):
        # override SocketServer.BaseServer
        print >>sys.stderr, '-'*40
        print >>sys.stderr, 'Exception happened during processing of request from', client_address
        traceback.print_exc()
        print >>sys.stderr, '-'*40


class ThreadingHTTPServer6(ThreadingHTTPServer):
    # listening on IPv6 address
    address_family = socket.AF_INET6


class SimpleHTTPProxyHandler(BaseHTTPRequestHandler):
    global_lock = Lock()
    conn_table = {}
    timeout = 2               # timeout with clients, set to None not to make persistent connection
    upstream_timeout = 115    # timeout with upstream servers, set to None not to make persistent connection
    proxy_via = None          # pseudonym of the proxy in Via header, set to None not to modify original Via header

    def log_error(self, format_, *args):
        if format_ == "Request timed out: %r":
            return
        self.log_message(format_, *args)

    def do_CONNECT(self):
        # just provide a tunnel, transfer the data with no modification
        # override here if you need
        req = self

        req_body = None
        replaced_req_body = self.request_handler(req, req_body)
        if replaced_req_body is True:
            return

        req.path = "https://%s/" % req.path.replace(':443', '')
        u = urlsplit(req.path)
        address = (u.hostname, u.port or 443)
        try:
            conn = socket.create_connection(address)
        except socket.error:
            self.send_error(504)    # 504 Gateway Timeout
            return
        self.send_response(200, 'Connection Established')
        self.send_header('Connection', 'close')
        self.end_headers()

        conns = [self.connection, conn]
        keep_connection = True
        while keep_connection:
            keep_connection = False
            r_list, w_list, x_list = select.select(conns, [], conns, self.timeout)
            if x_list:
                break
            for r in r_list:
                other = conns[1] if r is conns[0] else conns[0]
                data = r.recv(8192)
                if data:
                    other.sendall(data)
                    keep_connection = True
        conn.close()

    def do_HEAD(self):
        self.do_SPAM()

    def do_GET(self):
        self.do_SPAM()

    def do_POST(self):
        self.do_SPAM()

    def do_SPAM(self):
        req = self
        content_length = int(req.headers.get('Content-Length', 0))
        if content_length > 0:
            req_body = self.rfile.read(content_length)
        else:
            req_body = None

        replaced_reqbody = self.request_handler(req, req_body)
        if replaced_reqbody is True:
            return
        elif replaced_reqbody is not None:
            req_body = replaced_reqbody
            if 'Content-Length' in req.headers:
                req.headers['Content-Length'] = str(len(req_body))

        # follow RFC 2616 requirements
        self.remove_hop_by_hop_headers(req.headers)
        if self.upstream_timeout:
            req.headers['Connection'] = 'Keep-Alive'
        else:
            req.headers['Connection'] = 'close'
        if self.proxy_via:
            self.modify_via_header(req.headers)

        try:
            res, res_data = self.request_to_upstream_server(req, req_body)
        except socket.error:
            self.send_error(504)    # 504 Gateway Timeout
            return

        content_encoding = res.headers.get('Content-Encoding', 'identity')
        res_body = self.decode_content_body(res_data, content_encoding)

        replaced_resbody = self.response_handler(req, req_body, res, res_body)
        if replaced_resbody is True:
            return
        elif replaced_resbody is not None:
            res_data = self.encode_content_body(replaced_resbody, content_encoding)
            if 'Content-Length' in res.headers:
                res.headers['Content-Length'] = str(len(res_data))
            res_body = replaced_resbody

        # follow RFC 2616 requirements
        self.remove_hop_by_hop_headers(res.headers)
        if self.timeout:
            res.headers['Connection'] = 'Keep-Alive'
        else:
            res.headers['Connection'] = 'close'
        if self.proxy_via:
            self.modify_via_header(res.headers)

        self.send_response(res.status, res.reason)
        for k, v in res.headers.items():
            if k == 'set-cookie':
                # Origin servers SHOULD NOT fold multiple Set-Cookie header fields into a single header field. [RFC 6265]
                for value in self.split_set_cookie_header(v):
                    self.send_header(k, value)
            else:
                self.send_header(k, v)
        self.end_headers()

        if self.command != 'HEAD':
            self.wfile.write(res_data)
            with self.global_lock:
                self.save_handler(req, req_body, res, res_body)

    def request_to_upstream_server(self, req, req_body):
        u = urlsplit(req.path)
        origin = (u.scheme, u.netloc)

        # An HTTP/1.1 proxy MUST ensure that any request message it forwards does contain
        # an appropriate Host header field that identifies the service being requested by the proxy. [RFC 2616]
        req.headers['Host'] = u.netloc
        selector = "%s?%s" % (u.path, u.query) if u.query else u.path

        while True:
            with self.lock_origin(origin):
                conn = self.open_origin(origin)
                try:
                    conn.request(req.command, selector, req_body, headers=dict(req.headers))
                except socket.error:
                    # Couldn't connect to the upstream server.
                    self.close_origin(origin)
                    raise
                try:
                    res = conn.getresponse(buffering=True)
                except httplib.BadStatusLine as e:
                    if e.line == "''":
                        # Presumably, the connection had been closed by the server.
                        # Go for a retry with a new connection.
                        self.close_origin(origin)
                        continue
                    else:
                        raise
                res_data = res.read()
                res.headers = res.msg    # so that res have the same attribute as req
                if not self.upstream_timeout or 'close' in res.headers.get('Connection', ''):
                    self.close_origin(origin)
                else:
                    self.reset_timer(origin)
            return res, res_data

    def lock_origin(self, origin):
        d = self.conn_table.setdefault(origin, {})
        if 'lock' not in d:
            d['lock'] = Lock()
        return d['lock']

    def open_origin(self, origin):
        conn = self.conn_table[origin].get('connection')
        if not conn:
            scheme, netloc = origin
            if scheme == 'https':
                conn = httplib.HTTPSConnection(netloc)
            else:
                conn = httplib.HTTPConnection(netloc)
            self.reset_timer(origin)
            self.conn_table[origin]['connection'] = conn
        return conn

    def reset_timer(self, origin):
        timer = self.conn_table[origin].get('timer')
        if timer:
            timer.cancel()
        if self.upstream_timeout:
            timer = Timer(self.upstream_timeout, self.close_origin, args=[origin])
            timer.daemon = True
            timer.start()
        else:
            timer = None
        self.conn_table[origin]['timer'] = timer

    def close_origin(self, origin):
        timer = self.conn_table[origin]['timer']
        if timer:
            timer.cancel()
        conn = self.conn_table[origin]['connection']
        conn.close()
        del self.conn_table[origin]['connection']

    def remove_hop_by_hop_headers(self, headers):
        hop_by_hop_headers = ['Connection', 'Keep-Alive', 'Proxy-Authenticate', 'Proxy-Authorization', 'TE', 'Trailers',
                              'Trailer', 'Transfer-Encoding', 'Upgrade']
        connection = headers.get('Connection')
        if connection:
            keys = re.split(r',\s*', connection)
            hop_by_hop_headers.extend(keys)

        for k in hop_by_hop_headers:
            if k in headers:
                del headers[k]

    def modify_via_header(self, headers):
        via_string = "%s %s" % (self.protocol_version, self.proxy_via)
        via_string = re.sub(r'^HTTP/', '', via_string)

        original = headers.get('Via')
        if original:
            headers['Via'] = original + ', ' + via_string
        else:
            headers['Via'] = via_string

    def decode_content_body(self, data, content_encoding):
        if content_encoding in ('gzip', 'x-gzip'):
            io = StringIO(data)
            with gzip.GzipFile(fileobj=io) as f:
                body = f.read()
        elif content_encoding == 'deflate':
            body = zlib.decompress(data)
        elif content_encoding == 'identity':
            body = data
        else:
            raise Exception("Unknown Content-Encoding: %s" % content_encoding)
        return body

    def encode_content_body(self, body, content_encoding):
        if content_encoding in ('gzip', 'x-gzip'):
            io = StringIO()
            with gzip.GzipFile(fileobj=io, mode='wb') as f:
                f.write(body)
            data = io.getvalue()
        elif content_encoding == 'deflate':
            data = zlib.compress(body)
        elif content_encoding == 'identity':
            data = body
        else:
            raise Exception("Unknown Content-Encoding: %s" % content_encoding)
        return data

    def split_set_cookie_header(self, value):
        re_cookies = r'([^=]+=[^,;]+(?:;\s*Expires=[^,]+,[^,;]+|;[^,;]+)*)(?:,\s*)?'
        return re.findall(re_cookies, value, flags=re.IGNORECASE)

    def get_capture_data(self, req, req_body, res, res_body):
        capture_data = {"query_param": "null",
                        "cookie": "null",
                        "basic_auth": "null",
                        "request_header": "null",
                        "request_data": "null",
                        "response_header": "null",
                        "response_data": "null",
                        "set_cookie": "null",
                        "html_title": "null"
                        }

        def parse_qsl(s):
            return '\n'.join("%-20s %s" % (k, v) for k, v in urlparse.parse_qsl(s, keep_blank_values=True))

        req_header_text = "%s %s %s\n%s" % (req.command, req.path, req.request_version, req.headers)
        res_header_text = "%d %s\n%s" % (res.status, res.reason, res.headers)

        capture_data["request_header"] = req_header_text
        # print with_color(33, req_header_text)

        u = urlparse.urlsplit(req.path)
        if u.query:
            query_text = parse_qsl(u.query)
            # print with_color(32, "==== QUERY PARAMETERS ====\n%s\n" % query_text)
            capture_data["query_param"] = query_text

        cookie = req.headers.get('Cookie', '')
        if cookie:
            cookie = parse_qsl(re.sub(r';\s*', '&', cookie))
            # print with_color(32, "==== COOKIE ====\n%s\n" % cookie)
            capture_data["cookie"] = cookie

        auth = req.headers.get('Authorization', '')
        if auth.lower().startswith('basic'):
            token = auth.split()[1].decode('base64')
            # print with_color(31, "==== BASIC AUTH ====\n%s\n" % token)
            capture_data["basic_auth"] = token

        if req_body is not None:
            req_body_text = None
            content_type = req.headers.get('Content-Type', '')

            if content_type.startswith('application/x-www-form-urlencoded'):
                req_body_text = parse_qsl(req_body)
            elif content_type.startswith('application/json'):
                try:
                    json_obj = json.loads(req_body)
                    json_str = json.dumps(json_obj, indent=2)
                    if json_str.count('\n') < 50:
                        req_body_text = json_str
                    else:
                        lines = json_str.splitlines()
                        req_body_text = "%s\n(%d lines)" % ('\n'.join(lines[:50]), len(lines))
                except ValueError:
                    req_body_text = req_body
            elif len(req_body) < 1024:
                req_body_text = req_body

            if req_body_text:
                # print with_color(32, "==== REQUEST BODY ====\n%s\n" % req_body_text)
                capture_data["request_data"] = req_body_text

        # print with_color(36, res_header_text)
        capture_data["response_header"] = res_header_text

        set_cookie = res.headers.get('Set-Cookie', '')
        if set_cookie:
            set_cookie = parse_qsl(re.sub(r';\s*', '&', set_cookie))
            # print with_color(31, "==== SET-COOKIE ====\n%s\n" % set_cookie)
            capture_data["set_cookie"] = set_cookie

        if res_body is not None:
            res_body_text = None
            content_type = res.headers.get('Content-Type', '')

            if content_type.startswith('application/json'):
                try:
                    json_obj = json.loads(res_body)
                    json_str = json.dumps(json_obj, indent=2)
                    if json_str.count('\n') < 50:
                        res_body_text = json_str
                    else:
                        lines = json_str.splitlines()
                        res_body_text = "%s\n(%d lines)" % ('\n'.join(lines[:50]), len(lines))
                except ValueError:
                    res_body_text = res_body
            elif content_type.startswith('text/html'):
                m = re.search(r'<title[^>]*>([\s\S]+?)</title>', res_body, re.I)
                if m:
                    h = HTMLParser()
                    html_title = h.unescape(m.group(1).decode('utf-8'))
                    # print with_color(32, "==== HTML TITLE ====\n%s\n" % html_title)
                    capture_data["html_title"] = html_title

            elif content_type.startswith('text/') and len(res_body) < 1024:
                res_body_text = res_body

            if res_body_text:
                # print with_color(32, "==== RESPONSE BODY ====\n%s\n" % res_body_text)
                capture_data["response_data"] = res_body_text

            return capture_data

    def show_capture_info(self, capture_data):

        req_header_text = capture_data["request_header"]
        print with_color(33, req_header_text)

        query_text = capture_data["query_param"]
        print with_color(32, "==== QUERY PARAMETERS ====\n%s\n" % query_text)

        cookie = capture_data["cookie"]
        print with_color(32, "==== COOKIE ====\n%s\n" % cookie)

        token = capture_data["basic_auth"]
        print with_color(31, "==== BASIC AUTH ====\n%s\n" % token)

        req_body_text = capture_data["request_data"]
        print with_color(32, "==== REQUEST BODY ====\n%s\n" % req_body_text)

        res_header_text = capture_data["response_header"]
        print with_color(36, res_header_text)

        set_cookie = capture_data["set_cookie"]
        print with_color(31, "==== SET-COOKIE ====\n%s\n" % set_cookie)

        html_title = capture_data["html_title"]
        print with_color(32, "==== HTML TITLE ====\n%s\n" % html_title)

        res_body_text = capture_data["response_data"]
        print with_color(32, "==== RESPONSE BODY ====\n%s\n" % res_body_text)

        pass

    def print_info(self, req, req_body, res, res_body):
        capture_data = {"query_param": "null",
                        "cookie": "null",
                        "basic_auth": "null",
                        "request_header": "null",
                        "request_data": "null",
                        "response_header": "null",
                        "response_data": "null",
                        "set_cookie": "null",
                        "html_title": "null"
                        }

        def parse_qsl(s):
            return '\n'.join("%-20s %s" % (k, v) for k, v in urlparse.parse_qsl(s, keep_blank_values=True))

        req_header_text = "%s %s %s\n%s" % (req.command, req.path, req.request_version, req.headers)
        res_header_text = "%d %s\n%s" % (res.status, res.reason, res.headers)

        print with_color(33, req_header_text)
        capture_data["request_header"] = req_header_text

        u = urlparse.urlsplit(req.path)
        if u.query:
            query_text = parse_qsl(u.query)
            print with_color(32, "==== QUERY PARAMETERS ====\n%s\n" % query_text)
            capture_data["query_param"] = query_text

        cookie = req.headers.get('Cookie', '')
        if cookie:
            cookie = parse_qsl(re.sub(r';\s*', '&', cookie))
            print with_color(32, "==== COOKIE ====\n%s\n" % cookie)
            capture_data["cookie"] = cookie

        auth = req.headers.get('Authorization', '')
        if auth.lower().startswith('basic'):
            token = auth.split()[1].decode('base64')
            print with_color(31, "==== BASIC AUTH ====\n%s\n" % token)
            capture_data["basic_auth"] = token

        if req_body is not None:
            req_body_text = None
            content_type = req.headers.get('Content-Type', '')

            if content_type.startswith('application/x-www-form-urlencoded'):
                req_body_text = parse_qsl(req_body)
            elif content_type.startswith('application/json'):
                try:
                    json_obj = json.loads(req_body)
                    json_str = json.dumps(json_obj, indent=2)
                    if json_str.count('\n') < 50:
                        req_body_text = json_str
                    else:
                        lines = json_str.splitlines()
                        req_body_text = "%s\n(%d lines)" % ('\n'.join(lines[:50]), len(lines))
                except ValueError:
                    req_body_text = req_body
            elif len(req_body) < 1024:
                req_body_text = req_body

            if req_body_text:
                print with_color(32, "==== REQUEST BODY ====\n%s\n" % req_body_text)
                capture_data["request_data"] = req_body_text

        print with_color(36, res_header_text)
        capture_data["response_header"] = res_header_text

        set_cookie = res.headers.get('Set-Cookie', '')
        if set_cookie:
            set_cookie = parse_qsl(re.sub(r';\s*', '&', set_cookie))
            print with_color(31, "==== SET-COOKIE ====\n%s\n" % set_cookie)
            capture_data["set_cookie"] = set_cookie

        if res_body is not None:
            res_body_text = None
            content_type = res.headers.get('Content-Type', '')

            if content_type.startswith('application/json'):
                try:
                    json_obj = json.loads(res_body)
                    json_str = json.dumps(json_obj, indent=2)
                    if json_str.count('\n') < 50:
                        res_body_text = json_str
                    else:
                        lines = json_str.splitlines()
                        res_body_text = "%s\n(%d lines)" % ('\n'.join(lines[:50]), len(lines))
                except ValueError:
                    res_body_text = res_body
            elif content_type.startswith('text/html'):
                m = re.search(r'<title[^>]*>([\s\S]+?)</title>', res_body, re.I)
                if m:
                    h = HTMLParser()
                    html_title = h.unescape(m.group(1).decode('utf-8'))
                    print with_color(32, "==== HTML TITLE ====\n%s\n" % html_title)
                    capture_data["html_title"] = html_title

            elif content_type.startswith('text/') and len(res_body) < 1024:
                res_body_text = res_body

            if res_body_text:
                print with_color(32, "==== RESPONSE BODY ====\n%s\n" % res_body_text)
                capture_data["response_data"] = res_body_text

            return capture_data

    def request_handler(self, req, req_body):
        # override here
        # return True if you sent the response here and the proxy should not connect to the upstream server
        # return replaced req_body (other than None and True) if you did
        pass

    def response_handler(self, req, req_body, res, res_body):
        # override here
        # return True if you sent the response here and the proxy should not connect to the upstream server
        # return replaced res_body (other than None and True) if you did
        pass

    def save_handler(self, req, req_body, res, res_body):
        # override here
        # this handler is called after the proxy sent a response to the client
        # this handler is thread-safe, because this handler is always called with a global lock
        # self.print_info(req, req_body, res, res_body)

        capture_data = self.get_capture_data(req, req_body, res, res_body)
        if IS_SHOW:
            self.show_capture_info(capture_data)
        pass


def start_proxy(handler_class=SimpleHTTPProxyHandler, server_class=ThreadingHTTPServer, protocol="HTTP/1.1"):
    bind_ip, port = None, None
    try:
        opts, args = getopt.getopt(sys.argv[1:], "i:p:h", [])
    except getopt.GetoptError, e:
        usage(str(e))
        return 1
    for opt, value in opts:
        if opt == "-i":
            bind_ip = value
        if opt == "-p":
            port = int(value)
        if opt == "-h":
            usage()
            return 0

    if bind_ip is None:
        local_hostname = socket.gethostname()
        bind_ip = socket.gethostbyname(local_hostname)
    if port is None:
        port = 8080

    server_address = (bind_ip, port)

    handler_class.protocol_version = protocol
    httpd = server_class(server_address, handler_class)

    sa = httpd.socket.getsockname()
    print "Serving HTTP on", sa[0], "port", sa[1], "..."
    httpd.serve_forever()


if __name__ == '__main__':
    start_proxy()

    # use below for listening on IPv6 address
    # start_proxy(ServerClass=ThreadingHTTPServer6)
